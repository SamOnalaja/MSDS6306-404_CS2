---
title: "Case Study 2"
author: "Mai Loan Tran, Zackary Gill"
date: "November 27, 2018"
output: html_document
---

```{r}
library(caret)
library(MASS)

#Reads in the files
df <- read.csv("csv/CaseStudy2-data.csv")
testset <- read.csv("csv/CaseStudy2Validation.csv")

#Sets the reference level to No so that it is predicting Yes
df$Attrition <- relevel(df$Attrition, ref = "No")
testset$Attrition <- relevel(testset$Attrition, ref = "No")

#Creates the prediction and sets the values to Yes/No
predictyn <- function(fit, test)
{
  p1 <- ifelse(predict(fit, test) > 0.5, "Yes", "No")
  p1
}

#-------------Plotting everything... why?... why not-------------
pairs(df[,c(3,2,4:8)])
pairs(df[,c(3,9:16)])
pairs(df[,c(3,17:23)])
pairs(df[,c(3,24:30)])
pairs(df[,c(3,31:38)])

#--------------------All of the column names------------
#Age + BusinessTravel + DailyRate + Department + DistanceFromHome + Education + EducationField + EmployeeCount + EnvironmentSatisfaction + Gender + HourlyRate + JobInvolvement + JobLevel + JobRole + JobSatisfaction + MaritalStatus + MonthlyIncome + MonthlyRate + NumCompaniesWorked + OverTime + PercentSalaryHike + PerformanceRating + RelationshipSatisfaction + StandardHours + StockOptionLevel + TotalWorkingYears + TrainingTimesLastYear + WorkLifeBalance + YearsAtCompany + YearsInCurrentRole + YearsSinceLastPromotion + YearsWithCurrManager

#Not necessary in model:
#ID, EmployeeNumber, Over18, Rand (what even is that?), StandardHours, EmployeeCount

#dfc is the cleaned data (gets rid of factor with only 1 level)
dfc <- df
dfc$Over18 <- NULL

#-------------Cross Validation------------------
set.seed(1)
train_perc <- 0.5
samplesize <- length(df$Attrition)
train_indices = sample(seq(1, samplesize,length = samplesize), train_perc*samplesize)
dfc.train <- dfc[train_indices,]
dfc.test <- dfc[-train_indices,]

#Automatically selecting explainatory variables
full.model <- glm(Attrition~., data = dfc.train, family="binomial")

#Stepwise
step.model <- stepAIC(full.model, direction = c("both"), trace=FALSE)

#Backward
back.model <- stepAIC(full.model, direction = c("backward"), trace=FALSE)

#Forward
forw.model <- stepAIC(full.model, direction = c("forward"), trace=FALSE)

#Custom
cust.model <- glm(Attrition~Age + BusinessTravel + DailyRate + Department + DistanceFromHome + Education + EducationField + EmployeeCount + EnvironmentSatisfaction + Gender + HourlyRate + JobInvolvement + JobLevel + JobRole + JobSatisfaction + MaritalStatus + MonthlyIncome + MonthlyRate + NumCompaniesWorked + OverTime + PercentSalaryHike + PerformanceRating + RelationshipSatisfaction + StandardHours + StockOptionLevel + TotalWorkingYears + TrainingTimesLastYear + WorkLifeBalance + YearsAtCompany + YearsInCurrentRole + YearsSinceLastPromotion + YearsWithCurrManager, data = dfc.train, family="binomial")

#Tests the models
#WARNING: prediction from a rank-deficient fit may be misleading
#indicates that we have to many explainatory variables (i think)
pred.cust <- as.vector(predictyn(cust.model, dfc.test))
pred.step <- as.vector(predictyn(step.model, dfc.test))
pred.back <- as.vector(predictyn(back.model, dfc.test))
pred.forw <- as.vector(predictyn(forw.model, dfc.test))

#Creates the confusion matrix with all those stats
cust.mat <- confusionMatrix(table(dfc.test$Attrition, pred.cust))
step.mat <- confusionMatrix(table(dfc.test$Attrition, pred.step))
back.mat <- confusionMatrix(table(dfc.test$Attrition, pred.back))
forw.mat <- confusionMatrix(table(dfc.test$Attrition, pred.forw))

#Prints out just the accuracy % of the models
acc <- as.data.frame(cbind(cust.mat$overall[1]*100, step.mat$overall[1]*100, back.mat$overall[1]*100, forw.mat$overall[1]*100))
names(acc) <- c("Custom", "Stepwise", "Backward", "Forward")
acc

```
