---
title: "Talent Management"
author: "Mai Loan Tran, Zackary Gill"
date: "December 3, 2018"
output: html_document
---

##Executive Summary
#### Talent management is an iterative process of developing and retaining employees. Our analysis yielded that there are eleven (11) factors that contribute to turnover with an overall 87.3% accuracy. While there were positive relationships between the varying satisfaction metrics recently collected by job roles, the differences were not statistically significant.

##Introduction
#### DDSAnalytics is tasked with predicting employee turnover by conducting an analysis of employee data for the purpose of talent management. While seeking to determine factors that lead to attrition and identify job role specific trends, our deliverable is to build a model to predict attrition with at least 60% accuracy.

```{r preparation, echo=FALSE, warning=FALSE, message=FALSE, comment=NA}
library(caret)
library(MASS)
library(lattice)
library(ggplot2)
library(dplyr)
library(onewaytests)
library(agricolae)

#Reads in the files
dfTrain <- read.csv("csv/CaseStudy2-data.csv")
dfVal <- read.csv("csv/CaseStudy2Validation.csv")

head(dfTrain)
```
##Analysis
####We began our data analysis by plotting all the variables to identify the correlation and direction of the relationship between the pairs of variables. This was done in order to visually see if any one factor heavily contributed to Attrition. Below is a sample of the plotting done between Attrition and the other variables.
```{r EDA, echo=FALSE, warning=FALSE, message=FALSE, comment=NA}
#-------------Scatterplot matrices of all variables to identify correlations between pairs of variables within the data set-------------
pairs(dfTrain[,c(3,2,4:8)])
#pairs(dfTrain[,c(3,9:16)])
#pairs(dfTrain[,c(3,17:23)])
#pairs(dfTrain[,c(3,24:30)])
#pairs(dfTrain[,c(3,31:37)])

#Back up the Over18 column for the future
Over18.test <- dfTrain$Over18
Over18.val <- dfVal$Over18

#Gets rid of variable with only 1 level
dfTrain$Over18 <- NULL
dfVal$Over18 <- NULL

#-------------------Analysis of Job Role Specific Trends--------------------
#Create function to calculate the amount into a percentage and process the transformation to a table and back
makereadyforplot <- function(df)
{
  df1 <- table(df)
  df2 <- df1
  for(i in c(1:length(df1[,1])))
  {
    for(j in c(1:4))
    {
      df2[i,j] <- round(100*df1[i,j]/(df1[i,1]+df1[i,2]+df1[i,3]+df1[i,4]),0)
    }
  }
  
  as.data.frame(df2)
}
```

#### Next we looked for the relationship between job role and the differing satisfaction metrics from the recent survey responses. For each of these we used Welch's ANOVA and Fisher's LSD (with Bonferroni correction).
#### While there was not a statistical significance in job satisfaction beteen the roles (p-value 0.9079), Research Scientists and Healthcare Representatives both have the highest equal mean in job satisfaction at 2.80 in Medium-High range. Human Resources have the lowest mean at 2.57.
```{r job_satisfaction_by_role, echo=FALSE, warning=FALSE, message=FALSE, comment=NA}
#Gets only the rows we want and make sure they are always in the same order
dfTrain.js <- dfTrain[,c("JobRole","JobSatisfaction")]
dfTrain2 <- makereadyforplot(dfTrain.js)

#Plot Job Satisifaction by Role
ggplot(data = dfTrain2, aes(x = factor(JobRole), y=Freq, group=JobSatisfaction, fill = JobSatisfaction)) +
  geom_bar(stat = "identity", position = "dodge") +
  xlab("Job Role") +
  ylab("Percent") +
  geom_text(size=2.5, vjust=-0.1, aes(label= paste(Freq,"%",sep="")), position=position_dodge(width=0.95)) +
  scale_fill_brewer(palette = "Set1") + 
  ggtitle("Job Satisfaction by Role") +
  theme(legend.position="top",plot.title = element_text(hjust = 0.5),axis.text.x = element_text(angle = 90))

#Welch's ANOVA for Job Satisfaction
output.js.welch = welch.test(JobSatisfaction~JobRole,data=dfTrain.js)

#Fisher LSD with Bonferroni correction 
aov.js = aov(JobSatisfaction~JobRole,data=dfTrain.js)
output.js.bon = LSD.test(aov.js,"JobRole", p.adj="bonferroni")
output.js.bon$groups

```
####The mean environment satisfaction for all job roles is 2.71 in Medium-High range whereas Manufacturing Directors have the highest mean environment satisfaction at 2.90 and Research Directors have the lowest mean environment satisfaction at 2.39. The difference is not statistically significant at p-value 0.2330.
```{r environment_satisfaction_by_role, echo=FALSE, warning=FALSE, message=FALSE, comment=NA}
#Plot Environment Satisfaction by Role
dfTrain.es <- dfTrain[,c("JobRole","EnvironmentSatisfaction")]
dfTrain3 <- makereadyforplot(dfTrain.es)

ggplot(data = dfTrain3, aes(x = factor(JobRole), y=Freq, group=EnvironmentSatisfaction, fill = EnvironmentSatisfaction)) +
  geom_bar(stat = "identity", position = "dodge") +
  xlab("Job Role") +
  ylab("Percent") +
  geom_text(size=2.5, vjust=-0.1, aes(label= paste(Freq,"%",sep="")), position=position_dodge(width=.95)) +
  scale_fill_brewer(palette = "Set2") + 
  ggtitle("Environment Satisfaction by Role") +
  theme(legend.position="top",plot.title = element_text(hjust = 0.5),axis.text.x = element_text(angle = 90))

#Welch's ANOVA for Environment Satisfaction
output.es.welch = welch.test(EnvironmentSatisfaction~JobRole,data=dfTrain.es)

#Fisher LSD with Bonferroni correction
aov.es = aov(EnvironmentSatisfaction~JobRole,data=dfTrain.es)
output.es.bon = LSD.test(aov.es,"JobRole", p.adj="bonferroni")
output.es.bon$groups
```
####The mean relationship satisfaction for all job roles ranged from 2.50 to 2.77, albeit at a p-value 0.9362, the difference is not statistically significant between the roles. Managers have the highest mean relationship satisfaction whereas Sales Representatives have the lowest mean.
```{r relationship_satisfaction_by_role, echo=FALSE, warning=FALSE, message=FALSE, comment=NA}
#Plot Relationship Satisfaction by Role
dfTrain.rs <- dfTrain[,c("JobRole","RelationshipSatisfaction")]
dfTrain4 <- makereadyforplot(dfTrain.rs)

ggplot(data = dfTrain4, aes(x = factor(JobRole), y=Freq, group=RelationshipSatisfaction, fill = RelationshipSatisfaction)) +
  geom_bar(stat = "identity", position = "dodge") +
  xlab("Job Role") +
  ylab("Percent") +
  geom_text(size=2.5, vjust=-0.1, aes(label= paste(Freq,"%",sep="")), position=position_dodge(width=.95)) +
  scale_fill_brewer(palette = "Set3") + 
  ggtitle("Relationship Satisfaction by Role") +
  theme(legend.position="top",plot.title = element_text(hjust = 0.5),axis.text.x = element_text(angle = 90))

#Welch's ANOVA for Relationship Satisfaction
output.rs.welch = welch.test(RelationshipSatisfaction~JobRole,data=dfTrain.rs)

#Fisher LSD with Bonferroni correction
aov.rs = aov(RelationshipSatisfaction~JobRole,data=dfTrain.rs)
output.rs.bon = LSD.test(aov.rs,"JobRole", p.adj="bonferroni")
output.rs.bon$groups
```
####55% or more of the survey responses within each job role suggest a better work life balance. Human Resources personnel have the highest mean at 3.0 compared to Research Scientists with the lowest mean work life balance at 2.67.
```{r worklifebalance_satisfaction_by_role, echo=FALSE, warning=FALSE, message=FALSE, comment=NA}
#Plot Work Life Balance by Role
dfTrain.wlb <- dfTrain[,c("JobRole","WorkLifeBalance")]
dfTrain5 <- makereadyforplot(dfTrain.wlb)

ggplot(data = dfTrain5, aes(x = factor(JobRole), y=Freq, group=WorkLifeBalance, fill = WorkLifeBalance)) +
  geom_bar(stat = "identity", position = "dodge") +
  xlab("Job Role") +
  ylab("Percent") +
  geom_text(size=2.5, vjust=-0.1, aes(label= paste(Freq,"%",sep="")), position=position_dodge(width=.95)) +
  scale_fill_brewer(palette = "Set1") + 
  ggtitle("Work Life Balance by Role") +
  theme(legend.position="top",plot.title = element_text(hjust = 0.5),axis.text.x = element_text(angle = 90))

#Welch's ANOVA for Work Life Balance Satisfaction
output.wlb.welch = welch.test(WorkLifeBalance~JobRole,data=dfTrain.wlb)

#Fisher LSD with Bonferroni correction
aov.wlb = aov(WorkLifeBalance~JobRole,data=dfTrain.wlb)
output.wlb.bon = LSD.test(aov.wlb,"JobRole", p.adj="bonferroni")
output.wlb.bon$groups
```
##Prediction Conclusion
####With an 87.3% overall accuracy, our custom regression model identified that
business travel, commute distance, environment satisfaction, job involvement, job role, job satisfaction, marital status, number of companies worked, overtime, relationship satisfaction, and years at company are factors that contribute to attrition. Managing these factors in developing and retaining employees could reduce and prevent attrition.
```{r predict, echo=FALSE, warning=FALSE, message=FALSE, comment=NA}
#Sets the reference level to 'No' so that it is predicting 'Yes'
dfTrain$Attrition <- relevel(dfTrain$Attrition, ref = "No")
dfVal$Attrition <- relevel(dfVal$Attrition, ref = "No")

#Creates the prediction and sets the values to Yes/No
predictyn <- function(fit, test)
{
  p1 <- ifelse(predict(fit, test, type="response") > 0.5, "Yes", "No")
  p1
}

#-------------Cross Validation------------------
set.seed(1)
#train_perc <- 0.5
#samplesize <- length(dfTrain$Attrition)
#train_indices = sample(seq(1, samplesize,length = samplesize), train_perc*samplesize)
#dfTrain.train <- dfTrain[train_indices,]
#dfTrain.test <- dfTrain[-train_indices,]

#--------------------All of the variable names------------
#Age + BusinessTravel + DailyRate + Department + DistanceFromHome + Education + EducationField + EmployeeCount + EnvironmentSatisfaction + Gender + HourlyRate + JobInvolvement + JobLevel + JobRole + JobSatisfaction + MaritalStatus + MonthlyIncome + MonthlyRate + NumCompaniesWorked + OverTime + PercentSalaryHike + PerformanceRating + RelationshipSatisfaction + StandardHours + StockOptionLevel + TotalWorkingYears + TrainingTimesLastYear + WorkLifeBalance + YearsAtCompany + YearsInCurrentRole + YearsSinceLastPromotion + YearsWithCurrManager

#Determined the following variables to be unnecessary in the model:
#ID, EmployeeNumber, Over18, Rand, StandardHours, EmployeeCount

#Aparently we are no longer splitting up the data forcross validation
dfTrain.train <- dfTrain
dfTrain.test <- dfVal

#Automatically selecting explanatory variables
full.model <- glm(Attrition~., data = dfTrain.train, family="binomial")

#Stepwise
step.model <- stepAIC(full.model, direction = c("both"), trace=FALSE)

#Backward
back.model <- stepAIC(full.model, direction = c("backward"), trace=FALSE)

#Forward
forw.model <- stepAIC(full.model, direction = c("forward"), trace=FALSE)

#Custom Attrition w/Acc 86
#cust.model <- glm(Attrition~BusinessTravel + DistanceFromHome + EnvironmentSatisfaction + JobInvolvement + JobSatisfaction + MaritalStatus + NumCompaniesWorked + OverTime + TotalWorkingYears + WorkLifeBalance + YearsInCurrentRole + YearsSinceLastPromotion, data = dfTrain.train, family="binomial")

#Custom Attrition w/Acc 87.3%
cust.model <- glm(Attrition~BusinessTravel + DistanceFromHome + EnvironmentSatisfaction + JobInvolvement + JobRole + JobSatisfaction + MaritalStatus + NumCompaniesWorked + OverTime + RelationshipSatisfaction + YearsAtCompany, data = dfTrain.train, family="binomial")

#Tests the models
#'WARNING: prediction from a rank-deficient fit may be misleading' suggest that we have too many explanatory variables
pred.cust <- as.vector(predictyn(cust.model, dfTrain.test))
pred.step <- as.vector(predictyn(step.model, dfTrain.test))
pred.back <- as.vector(predictyn(back.model, dfTrain.test))
pred.forw <- as.vector(predictyn(forw.model, dfTrain.test))

#Creates the confusion matrix with all those stats
cust.mat <- confusionMatrix(table(dfTrain.test$Attrition, pred.cust))
step.mat <- confusionMatrix(table(dfTrain.test$Attrition, pred.step))
back.mat <- confusionMatrix(table(dfTrain.test$Attrition, pred.back))
forw.mat <- confusionMatrix(table(dfTrain.test$Attrition, pred.forw))

#cust.mat
#step.mat
#back.mat
#forw.mat

#Prints out just the overall accuracy % of the models
acc <- as.data.frame(cbind(cust.mat$overall[1]*100, step.mat$overall[1]*100, back.mat$overall[1]*100, forw.mat$overall[1]*100))
names(acc) <- c("Custom", "Stepwise", "Backward", "Forward")
numvar <- as.data.frame(cbind( (length(names(cust.model$model))-1), (length(names(step.model$model))-1), (length(names(back.model$model))-1), (length(names(forw.model$model))-1)))
names(numvar) <- c("Custom", "Stepwise", "Backward", "Forward")
model.info <- rbind(acc, numvar)
rownames(model.info) <- c("Accuracy", "Num Terms")
model.info
#cust.mat$table

#---------------Choose the best prediction and write to file--------------
#The custom model predictions for the file
dfPreds <- as.data.frame( cbind( dfVal$ID, pred.cust ) )
names(dfPreds) <- c("ID", "Attrition")

write.csv(dfPreds, "Case2PredictionsGillTran.csv", row.names = FALSE)
```

